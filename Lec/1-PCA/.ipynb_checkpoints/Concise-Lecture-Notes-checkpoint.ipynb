{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af90b7d5",
   "metadata": {},
   "source": [
    "# Review of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85439dd0",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a147483",
   "metadata": {},
   "source": [
    "1. CDF always exists.\n",
    "\n",
    "2. Definition of PDF: $f_X(x)$ is said to be a pdf of r.v. X if $P(X\\le x)=\\int_{-\\infty}^x f_X(x)dx$\n",
    "\n",
    "3. PDF/PMF may not exist. (e.g. r.v.'s which are neither continuous nor discrete.)\n",
    "\n",
    "4. PDF is NOT unique. (因為單點機率=0)\n",
    "\n",
    "     e.g. Consider $f_X(x)$ to be a normal pdf.\n",
    "     \n",
    "     Define $\\tilde f_X(x)=\\begin{cases}f_X(x) & \\text{ if } x\\ne0\\\\ e^{10} & \\text{ if } x=0\\end{cases}$\n",
    "\n",
    "     Then $\\tilde f_X(x)$ is still a normal pdf since $P(X\\le x)=\\int_{-\\infty}^x f_X(x)dx=\\int_{-\\infty}^x \\tilde f_X(x)dx$.\n",
    "     \n",
    "     \n",
    "5. CLT: Given $X_1,\\dots,X_n\\sim i.i.d. F_{X}(\\cdot)$, if $E(X)< \\infty$, then $\\sqrt{n} (\\bar{X}_n-\\mu)\\xrightarrow{d}N(0, \\sigma^2)$\n",
    "\n",
    "    The CLT states that sum of independent small distubance is Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d285865",
   "metadata": {},
   "source": [
    "## Multivariate Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46531aad",
   "metadata": {},
   "source": [
    "Consider a multivariate normal r.v., $\\mathbb X\\sim N(\\mathbb\\mu, \\Sigma), \\mathbb X =(X_1, \\dots, X_p)^T$ where each $X_i$ is a univariate normal, i.e.,  $X_i\\sim N(\\mu_i, \\sigma_i^2=\\sigma_{ii})$\n",
    "\n",
    "Assume $\\Sigma$ is diagonal, i.e, $Cov(X_i,X_j)=0\\implies$ $X_i$ are independence (This is only true for jointly normal distribution).\n",
    "\n",
    "Then $f_{\\mathbb X}{(x_1, ..., x_p)}=f_{X_1}(x_1)\\times \\cdots \\times f_{X_p}(x_p)$\n",
    "\n",
    "$\\text{Proof:}$\n",
    "\n",
    "Consider p=2 for simplicity.\n",
    "\n",
    "$\\Sigma=\\begin{bmatrix}\\sigma_{11} & 0 \\\\ 0&\\sigma_{22}\\end{bmatrix}$\n",
    "\n",
    "$\\Sigma^{-1}=\\frac{1}{\\sigma_{11}\\sigma_{22}-0}\\begin{bmatrix}\\sigma_{22} & 0 \\\\ 0&\\sigma_{11}\\end{bmatrix}=\\begin{bmatrix}1/\\sigma_{11} & 0 \\\\ 0&1/\\sigma_{22}\\end{bmatrix}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_{\\mathbb X}(x_1, x_2)&=\\frac{1}{\\sqrt{2\\pi}^p}(\\frac{1}{det(\\Sigma)})^{1/2}exp(-\\frac12 (\\mathbb x-\\mathbb\\mu)^T\\Sigma^{-1}(\\mathbb  x-\\mathbb \\mu))\\\\\n",
    "&=\\frac{1}{\\sqrt{2\\pi}^2}(\\frac{1}{\\sigma_{11}\\sigma_{22}})^{1/2}exp(-\\frac12 (\\mathbb x-\\mathbb\\mu)^T\\Sigma^{-1}(\\mathbb  x-\\mathbb \\mu))\\\\\n",
    "&=\\frac{1}{\\sqrt{2\\pi}^2}(\\frac{1}{\\sigma_{11}\\sigma_{22}})^{1/2}exp(-\\frac12 (\\frac{(x_1-\\mu_1)^2}{\\sigma_{11}}+\\frac{(x_2-\\mu_2)^2}{\\sigma_{22}}))\\\\\n",
    "&=f_{X_1(x_1)}f_{X_2(x_2)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e133de",
   "metadata": {},
   "source": [
    "Contour Plot:\n",
    "\n",
    "$f_{\\mathbb X}(x_1, x_2)=k\\iff \\frac{(x_1-\\mu_1)^2}{\\sigma_{11}}+\\frac{(x_2-\\mu_2)^2}{\\sigma_{22}}=k$\n",
    "\n",
    "which is an ellipse in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f47633",
   "metadata": {},
   "source": [
    "## True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724832bd",
   "metadata": {},
   "source": [
    "1. Let $\\mathbb X=(X_1,...,X_p)^T\\sim N(\\mathbb\\mu, \\Sigma)$. If $X_1,X_2,··· ,X_p$ are mutually independent, $X_i ⊥ X_j,∀i \\ne j$. Are $X_1,X_2,··· ,X_p$ independent?\n",
    "\n",
    "   Yes, but this is Only True for jointly normal distribution since $X_i\\perp X_j\\implies Cov(X_i, X_j)=0\\implies \\Sigma\\text{ is diagonal}\\implies X_1, X_2, ..., X_p$ are independent\n",
    "\n",
    "\n",
    "\n",
    "2. Let $X_1, X_2$ be two normal random variables. Does $Cov(X_1, X_2) = 0$ imply $X_1 ⊥ X_2$?\n",
    "\n",
    "   No, This is only true for jointly normal distribution. Notice that $X_1, X_2$ be two normal random variables $\\ne$ $X_1,X_2$ jointly normal\n",
    " \n",
    "   An explanation is [here](https://en.wikipedia.org/wiki/Normally_distributed_and_uncorrelated_does_not_imply_independent).\n",
    "   \n",
    "\n",
    "3. $X_1 , X_2$ are two normal random variable. Is $X_1 + X_2$ also normal?\n",
    "\n",
    "    No, again this is only true for jointly normal or you may need the independence assumption.\n",
    "\n",
    "    If the two normal random variables are not independent, then their sum is not necessarily normal.\n",
    "    \n",
    "    Definition: Two random variables $X$ and $Y$ are said to be bivariate normal, or jointly normal, if $aX+bY$ has a normal distribution for all $a,b∈ℝ$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d9cca",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e875b9",
   "metadata": {},
   "source": [
    "Show that if $Y=aX+b$ then $Corr(X,Y)=1$\n",
    "\n",
    "$\\text{Proof:}$\n",
    "\n",
    "Notice that $Cov(X, Y)=Cov(X, aX+b)=aVar(X)$ and $Var(Y)=a^2Var(X)$\n",
    "\n",
    "$$Corr(X, Y)=\\frac{Cov(X, Y)}{\\sqrt{Var(X)}\\sqrt{Var(Y)}}=\\frac{aVar(X)}{aVar(X)}=1$$\n",
    "\n",
    "$\\text{Remark: The converse is also true, i.e., }Corr(X,Y)=1\\implies \\exists a, b \\ni Y=aX+b$\n",
    "\n",
    "This also shows that covariance captures linear dependence (but not non-linear relationship)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6db0b2",
   "metadata": {},
   "source": [
    "## Applications of Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68224d",
   "metadata": {},
   "source": [
    "For example, Risk Hedging. Consider two stocks with returns $R_1, R_2$, with $E(R_1)=E(R_2)>0$, $Var(R_1)=Var(R_2)>0$, and $Cov(R_1, R_2)<0$\n",
    "\n",
    "Assume a portfolio $aR_1+bR_2$, with $a+b=1, 0<a<1, 0<b<1$\n",
    "\n",
    "Then $E(aR_1+bR_2)=aE(R_1)+bE(R_2)$ and $Var(aR_1+bR_2)=a^2Var(R_1)+b^2Var(R_2)+2ab\\underbrace{Cov(R_1,R_2)}_{<0}$\n",
    "\n",
    "Hence, the variance of the portfolio must be smaller than the individual stock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613a3eb",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2326bae",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e9538",
   "metadata": {},
   "source": [
    "project $\\vec a$ to $\\vec b$:  $\\frac{\\vec a\\cdot \\vec b}{||\\vec b||^2}\\vec b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8d311",
   "metadata": {},
   "source": [
    "Smaller reconstruction error $\\iff$ The projected variable has larger variance (less information loss)\n",
    "\n",
    "Given $\\mathbb X=(X_1,...,X_p)^T$ a random vector, we want to find a direction $a$ so that $Var(a^TX)$ is largest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b347bb",
   "metadata": {},
   "source": [
    "Consider $\\mathbb X=(X_1,...,X_p)^T$, $E(\\mathbb X)=\\mathbb 0$, $Cov(\\mathbb X)=\\Sigma$\n",
    "\n",
    "The first principal component (PC) $a_1$ is defined to be\n",
    "\n",
    "$$\\max_{a_1} Var(a_1^T\\mathbb X)\\\\\n",
    "s.t. ||a_1||=\\sqrt{a_1^Ta_1}=1$$\n",
    "\n",
    "The second PC is given by \n",
    "\n",
    "$$\\max_{a_2} Var(a_2^T\\mathbb X)\\\\\n",
    "s.t. ||a_2||=1, a_1^Ta_2=0 \\text{ (orthogonal)}$$\n",
    "\n",
    "\n",
    "The j-th PC, $j\\le p$ is given by \n",
    "\n",
    "$$\\max_{a_j}Var(a_j^T \\mathbb X)\\\\ \n",
    "s.t. ||a_j||=1, a_j^Ta_i=0, \\forall i<j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85170457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613db740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d1179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e9bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67369bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
